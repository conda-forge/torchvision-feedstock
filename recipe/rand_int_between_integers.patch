diff --git a/test/test_transforms.py b/test/test_transforms.py
index 7581bf3322..44b6051abb 100644
--- a/test/test_transforms.py
+++ b/test/test_transforms.py
@@ -1623,8 +1623,8 @@ def test_augmix(fill, severity, mixture_width, chain_depth, all_ops, grayscale):
 def test_random_crop():
     height = random.randint(10, 32) * 2
     width = random.randint(10, 32) * 2
-    oheight = random.randint(5, (height - 2) / 2) * 2
-    owidth = random.randint(5, (width - 2) / 2) * 2
+    oheight = random.randint(5, (height - 2) // 2) * 2
+    owidth = random.randint(5, (width - 2) // 2) * 2
     img = torch.ones(3, height, width, dtype=torch.uint8)
     result = transforms.Compose(
         [
@@ -1673,8 +1673,8 @@ def test_random_crop():
 def test_center_crop():
     height = random.randint(10, 32) * 2
     width = random.randint(10, 32) * 2
-    oheight = random.randint(5, (height - 2) / 2) * 2
-    owidth = random.randint(5, (width - 2) / 2) * 2
+    oheight = random.randint(5, (height - 2) // 2) * 2
+    owidth = random.randint(5, (width - 2) // 2) * 2
 
     img = torch.ones(3, height, width, dtype=torch.uint8)
     oh1 = (height - oheight) // 2
diff --git a/test/test_transforms_video.py b/test/test_transforms_video.py
index 21594868f0..4ad57e6a98 100644
--- a/test/test_transforms_video.py
+++ b/test/test_transforms_video.py
@@ -23,8 +23,8 @@ class TestVideoTransforms:
         numFrames = random.randint(4, 128)
         height = random.randint(10, 32) * 2
         width = random.randint(10, 32) * 2
-        oheight = random.randint(5, (height - 2) / 2) * 2
-        owidth = random.randint(5, (width - 2) / 2) * 2
+        oheight = random.randint(5, (height - 2) // 2) * 2
+        owidth = random.randint(5, (width - 2) // 2) * 2
         clip = torch.randint(0, 256, (numFrames, height, width, 3), dtype=torch.uint8)
         result = Compose(
             [
@@ -41,8 +41,8 @@ class TestVideoTransforms:
         numFrames = random.randint(4, 128)
         height = random.randint(10, 32) * 2
         width = random.randint(10, 32) * 2
-        oheight = random.randint(5, (height - 2) / 2) * 2
-        owidth = random.randint(5, (width - 2) / 2) * 2
+        oheight = random.randint(5, (height - 2) // 2) * 2
+        owidth = random.randint(5, (width - 2) // 2) * 2
         clip = torch.randint(0, 256, (numFrames, height, width, 3), dtype=torch.uint8)
         result = Compose(
             [
@@ -59,8 +59,8 @@ class TestVideoTransforms:
         numFrames = random.randint(4, 128)
         height = random.randint(10, 32) * 2
         width = random.randint(10, 32) * 2
-        oheight = random.randint(5, (height - 2) / 2) * 2
-        owidth = random.randint(5, (width - 2) / 2) * 2
+        oheight = random.randint(5, (height - 2) // 2) * 2
+        owidth = random.randint(5, (width - 2) // 2) * 2
 
         clip = torch.ones((numFrames, height, width, 3), dtype=torch.uint8) * 255
         oh1 = (height - oheight) // 2
